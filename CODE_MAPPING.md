# Mapping Code Files vá»›i Ká»‹ch Báº£n Há»‡ Thá»‘ng

File nÃ y mapping giá»¯a cÃ¡c pháº§n trong `openaq_kich_ban.md` vá»›i cÃ¡c file code tÆ°Æ¡ng á»©ng. Khi giÃ¡o viÃªn há»i "pháº§n nÃ y code á»Ÿ Ä‘Ã¢u", báº¡n cÃ³ thá»ƒ tra cá»©u nhanh.

---

## ğŸ“‹ Má»¥c lá»¥c

1. [BÆ°á»›c 1: Thu tháº­p Dá»¯ liá»‡u (Data Ingestion)](#bÆ°á»›c-1-thu-tháº­p-dá»¯-liá»‡u-data-ingestion)
2. [BÆ°á»›c 2: Batch Processing (Spark)](#bÆ°á»›c-2-batch-processing-spark)
3. [BÆ°á»›c 3: Load vÃ o ClickHouse](#bÆ°á»›c-3-load-vÃ o-clickhouse)
4. [BÆ°á»›c 4: PhÃ¢n tÃ­ch](#bÆ°á»›c-4-phÃ¢n-tÃ­ch)
5. [CÃ¡c Module Há»— trá»£](#cÃ¡c-module-há»—-trá»£)
6. [Cáº¥u hÃ¬nh vÃ  Setup](#cáº¥u-hÃ¬nh-vÃ -setup)
7. [ML Training](#ml-training)
8. [Web Application (Inference)](#web-application-inference)

---

## BÆ°á»›c 1: Thu tháº­p Dá»¯ liá»‡u (Data Ingestion)

### ğŸ“„ File chÃ­nh: `collect_data.py`

**Nhiá»‡m vá»¥:** Thu tháº­p dá»¯ liá»‡u tá»« OpenAQ API vÃ  gá»­i vÃ o Kafka

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Xá»­ lÃ½ tiá»n xá»­ lÃ½ (Pre-processing)** - Lá»c tráº¡m cÃ²n hoáº¡t Ä‘á»™ng | `get_alive_stations()` (dÃ²ng 53-115) | HÃ m lá»c cÃ¡c tráº¡m cÃ³ dá»¯ liá»‡u trong 7 ngÃ y gáº§n nháº¥t, cÃ³ PM2.5 hoáº·c PM10 |
| **QuÃ¡ trÃ¬nh thu tháº­p** - Láº¥y danh sÃ¡ch tráº¡m | `get_alive_stations()` (dÃ²ng 67-70) | Gá»i API `/locations` vá»›i filter theo quá»‘c gia |
| **QuÃ¡ trÃ¬nh thu tháº­p** - Láº¥y measurements | `fetch_measurements_for_sensor()` (dÃ²ng 118-177) | Gá»i API `/sensors/{sensor_id}/measurements/hourly` Ä‘á»ƒ láº¥y dá»¯ liá»‡u lá»‹ch sá»­ |
| **Xá»­ lÃ½ dá»¯ liá»‡u** - Chuyá»ƒn Ä‘á»•i Ä‘Æ¡n vá»‹ | `aqi_calculator.py` â†’ `convert_unit_to_standard()` | Import vÃ  sá»­ dá»¥ng tá»« module `aqi_calculator` |
| **Xá»­ lÃ½ dá»¯ liá»‡u** - TÃ­nh toÃ¡n AQI | `aqi_calculator.py` â†’ `calculate_aqi_for_pollutant()` | Import vÃ  sá»­ dá»¥ng tá»« module `aqi_calculator` |
| **Xá»­ lÃ½ dá»¯ liá»‡u** - PhÃ¢n loáº¡i AQI | `aqi_calculator.py` â†’ `get_aqi_category()` | Import vÃ  sá»­ dá»¥ng tá»« module `aqi_calculator` |
| **Output** - Gá»­i vÃ o Kafka | `send_to_kafka()` (dÃ²ng 180-186) | Gá»­i JSON message vÃ o topic `openaq-raw-measurements` |
| **Collect historical data** | `collect_historical_data()` (dÃ²ng 189-240) | HÃ m chÃ­nh Ä‘á»ƒ thu tháº­p dá»¯ liá»‡u lá»‹ch sá»­ |
| **Collect real-time data** | `collect_realtime_data()` (dÃ²ng 243-301) | HÃ m Ä‘á»ƒ thu tháº­p dá»¯ liá»‡u real-time (cháº¡y liÃªn tá»¥c) |
| **Entry point** | `main()` (dÃ²ng 304-365) | HÃ m main, xá»­ lÃ½ arguments, khá»Ÿi táº¡o Kafka producer |

**CÃ¡c hÃ m quan trá»ng:**
- `get_alive_stations()`: Lá»c vÃ  tráº£ vá» danh sÃ¡ch tráº¡m cÃ²n hoáº¡t Ä‘á»™ng
- `fetch_measurements_for_sensor()`: Láº¥y measurements tá»« OpenAQ API
- `collect_historical_data()`: Thu tháº­p dá»¯ liá»‡u lá»‹ch sá»­
- `collect_realtime_data()`: Thu tháº­p dá»¯ liá»‡u real-time
- `send_to_kafka()`: Gá»­i message vÃ o Kafka

**CÃ¡ch cháº¡y:**
```bash
python collect_data.py --mode historical --days 10000
```

---

## BÆ°á»›c 2: Batch Processing (Spark)

### ğŸ“„ File chÃ­nh: `spark/batch_processor.py`

**Nhiá»‡m vá»¥:** Xá»­ lÃ½ dá»¯ liá»‡u tá»« Kafka â†’ Bronze â†’ Silver â†’ Gold (pipeline tuáº§n tá»±)

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Bronze Layer** - Parse JSON | `process_kafka_to_bronze()` (dÃ²ng 80-133) | Äá»c tá»« Kafka, parse JSON, extract fields |
| **Bronze Layer** - Filter cÆ¡ báº£n | `process_kafka_to_bronze()` (dÃ²ng 111-115) | Filter null cho `datetime`, `location_id`, `parameter` |
| **Bronze Layer** - Partition | `process_kafka_to_bronze()` (dÃ²ng 118-120) | ThÃªm columns `year`, `month`, `day` |
| **Bronze Layer** - Write to MinIO | `process_kafka_to_bronze()` (dÃ²ng 125-129) | Ghi Parquet files vÃ o `s3a://air-quality-data/bronze/` |
| **Silver Layer** - Äá»c tá»« Bronze | `process_bronze_to_silver()` (dÃ²ng 136-179) | Load Parquet files tá»« Bronze layer |
| **Silver Layer** - Data Cleaning | `process_bronze_to_silver()` (dÃ²ng 145-158) | Chá»‰ giá»¯ `value_standard`, bá» `value`, `unit`, `ingestion_timestamp` |
| **Silver Layer** - Validation Filters | `process_bronze_to_silver()` (dÃ²ng 159-166) | Filter null, value >= 0, khÃ´ng NaN |
| **Silver Layer** - Write to MinIO | `process_bronze_to_silver()` (dÃ²ng 171-175) | Ghi Parquet files vÃ o `s3a://air-quality-data/silver/` |
| **Gold Layer** - Äá»c tá»« Silver | `process_silver_to_gold()` (dÃ²ng 182-222) | Load Parquet files tá»« Silver layer |
| **Gold Layer** - Aggregation | `process_silver_to_gold()` (dÃ²ng 191-209) | Group by `location_id` + `hour_datetime`, aggregate AQI, parameters, values |
| **Gold Layer** - Write to MinIO | `process_silver_to_gold()` (dÃ²ng 214-218) | Ghi Parquet files vÃ o `s3a://air-quality-data/gold/` |
| **Spark Session Setup** | `create_spark_session()` (dÃ²ng 48-77) | Cáº¥u hÃ¬nh Spark vá»›i MinIO S3, adaptive execution |
| **Entry point** | `main()` (dÃ²ng 225-260) | HÃ m main, xá»­ lÃ½ arguments, gá»i cÃ¡c hÃ m xá»­ lÃ½ theo thá»© tá»± |

**CÃ¡c hÃ m quan trá»ng:**
- `create_spark_session()`: Táº¡o Spark session vá»›i cáº¥u hÃ¬nh MinIO
- `process_kafka_to_bronze()`: Kafka â†’ Bronze
- `process_bronze_to_silver()`: Bronze â†’ Silver
- `process_silver_to_gold()`: Silver â†’ Gold

**CÃ¡ch cháº¡y:**
```bash
docker exec spark-batch spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.hadoop:hadoop-aws:3.3.4 \
  /app/spark/batch_processor.py --layer all
```

---

## BÆ°á»›c 3: Load vÃ o ClickHouse

### ğŸ“„ File chÃ­nh: `load_to_clickhouse.py`

**Nhiá»‡m vá»¥:** Äá»c Parquet files tá»« MinIO vÃ  load vÃ o ClickHouse tables

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Káº¿t ná»‘i MinIO** | `get_s3_filesystem()` (dÃ²ng 29-36) | Táº¡o S3 filesystem connection Ä‘áº¿n MinIO |
| **Káº¿t ná»‘i ClickHouse** | `get_clickhouse_client()` (dÃ²ng 39-49) | Táº¡o ClickHouse client connection |
| **Load Bronze** | `load_bronze_to_clickhouse()` (dÃ²ng 52-105) | Äá»c Parquet tá»« MinIO Bronze, insert vÃ o table `bronze_measurements` |
| **Load Silver** | `load_silver_to_clickhouse()` (dÃ²ng 108-165) | Äá»c Parquet tá»« MinIO Silver, insert vÃ o table `silver_measurements` |
| **Load Gold** | `load_gold_to_clickhouse()` (dÃ²ng 168-236) | Äá»c Parquet tá»« MinIO Gold, insert vÃ o table `gold_hourly_aqi` |
| **Entry point** | `main()` (dÃ²ng 239-285) | HÃ m main, xá»­ lÃ½ arguments, gá»i cÃ¡c hÃ m load theo layer |

**CÃ¡c hÃ m quan trá»ng:**
- `get_s3_filesystem()`: Káº¿t ná»‘i MinIO
- `get_clickhouse_client()`: Káº¿t ná»‘i ClickHouse
- `load_bronze_to_clickhouse()`: Load Bronze layer
- `load_silver_to_clickhouse()`: Load Silver layer
- `load_gold_to_clickhouse()`: Load Gold layer

**CÃ¡ch cháº¡y:**
```bash
python load_to_clickhouse.py --layer all
```

---

## BÆ°á»›c 4: PhÃ¢n tÃ­ch

### ğŸ“„ File: `clickhouse/init.sql`

**Nhiá»‡m vá»¥:** Táº¡o ClickHouse tables vÃ  materialized views

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Táº¡o database** | `clickhouse/init.sql` (dÃ²ng Ä‘áº§u) | `CREATE DATABASE IF NOT EXISTS air_quality` |
| **Táº¡o table bronze_measurements** | `clickhouse/init.sql` | Schema cho Bronze layer |
| **Táº¡o table silver_measurements** | `clickhouse/init.sql` | Schema cho Silver layer |
| **Táº¡o table gold_hourly_aqi** | `clickhouse/init.sql` | Schema cho Gold layer |
| **Táº¡o materialized view latest_aqi** | `clickhouse/init.sql` | View tá»± Ä‘á»™ng cáº­p nháº­t cho real-time queries |

**File SQL queries máº«u:** `clickhouse_queries.sql`
- Chá»©a cÃ¡c query vÃ­ dá»¥ Ä‘á»ƒ query ClickHouse
- KhÃ´ng pháº£i file cháº¡y tá»± Ä‘á»™ng, chá»‰ lÃ  reference

---

## CÃ¡c Module Há»— trá»£

### ğŸ“„ File: `aqi_calculator.py`

**Nhiá»‡m vá»¥:** TÃ­nh toÃ¡n AQI theo tiÃªu chuáº©n US EPA

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **US EPA AQI Breakpoints** | `AQI_BREAKPOINTS` (dÃ²ng 8-56) | Dictionary chá»©a breakpoints cho tá»«ng pollutant |
| **TÃ­nh toÃ¡n AQI** | `calculate_aqi_for_pollutant()` (dÃ²ng 59-88) | HÃ m tÃ­nh AQI báº±ng linear interpolation |
| **Chuyá»ƒn Ä‘á»•i Ä‘Æ¡n vá»‹** | `convert_unit_to_standard()` (dÃ²ng 91-112) | Convert vá» Ä‘Æ¡n vá»‹ chuáº©n US EPA (ppm cho O3, CO, SO2, NO2) |
| **PhÃ¢n loáº¡i AQI** | `get_aqi_category()` (dÃ²ng 115-128) | Tráº£ vá» category: Good, Moderate, Unhealthy for Sensitive Groups, etc. |

**ÄÆ°á»£c sá»­ dá»¥ng bá»Ÿi:**
- `collect_data.py`: TÃ­nh AQI khi thu tháº­p dá»¯ liá»‡u
- `app.py`: TÃ­nh AQI trong inference pipeline

---

## Cáº¥u hÃ¬nh vÃ  Setup

### ğŸ“„ File: `docker-compose.yml`

**Nhiá»‡m vá»¥:** Cáº¥u hÃ¬nh táº¥t cáº£ services (Kafka, MinIO, ClickHouse, Spark)

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Zookeeper** | `zookeeper` service (dÃ²ng 3-13) | Service cho Kafka |
| **Kafka** | `kafka` service (dÃ²ng 16-35) | Message queue, port 9092 |
| **MinIO** | `minio` service (dÃ²ng 38-57) | S3-compatible storage, ports 9000 (API), 9001 (Console) |
| **ClickHouse** | `clickhouse` service (dÃ²ng 60-79) | OLAP database, ports 8123 (HTTP), 9002 (Native) |
| **Spark Batch** | `spark-batch` service (dÃ²ng 82-106) | Spark container cho batch processing |

### ğŸ“„ File: `setup_minio_buckets.py`

**Nhiá»‡m vá»¥:** Táº¡o MinIO bucket `air-quality-data`

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Setup MinIO bucket** | `setup_minio()` (dÃ²ng 15-40) | Táº¡o bucket náº¿u chÆ°a tá»“n táº¡i |

**CÃ¡ch cháº¡y:**
```bash
python setup_minio_buckets.py
```

### ğŸ“„ File: `Dockerfile.spark`

**Nhiá»‡m vá»¥:** Build Docker image cho Spark container

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Spark container setup** | ToÃ n bá»™ file | CÃ i Ä‘áº·t Java 11, Python 3.11, PySpark, dependencies |

---

## ML Training

### ğŸ“„ File: `ml_training/data_loader.py`

**Nhiá»‡m vá»¥:** Load dá»¯ liá»‡u tá»« MinIO Gold layer cho ML training

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Load Gold layer** | `load_gold_layer()` (dÃ²ng 49-152) | Äá»c Parquet files tá»« MinIO Gold layer |
| **Feature Engineering** | `create_features()` (dÃ²ng 154-252) | Táº¡o 22 features: time, lag, rolling statistics, spatial, pollutant |
| **Train/Test Split** | `split_train_val_test()` (dÃ²ng 254-280) | Split theo thá»i gian: Train (â‰¤2023), Validation (2024), Test (>2024) |

**Class chÃ­nh:**
- `AirQualityDataLoader`: Class Ä‘á»ƒ load vÃ  preprocess dá»¯ liá»‡u

### ğŸ“„ File: `ml_training/train_lightgbm.py`

**Nhiá»‡m vá»¥:** Training model LightGBM

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Training LightGBM** | ToÃ n bá»™ file | Load data, create features, train LightGBM model, save model |

### ğŸ“„ File: `ml_training/train_xgboost.py`

**Nhiá»‡m vá»¥:** Training model XGBoost

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Training XGBoost** | ToÃ n bá»™ file | Load data, create features, train XGBoost model, save model |

### ğŸ“„ File: `ml_training/evaluate.py`

**Nhiá»‡m vá»¥:** ÄÃ¡nh giÃ¡ model performance

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Model evaluation** | ToÃ n bá»™ file | Load model, evaluate trÃªn test set, tÃ­nh metrics (RÂ², MAE, RMSE) |

### ğŸ“„ File: `ml_training/check_countries.py`

**Nhiá»‡m vá»¥:** Kiá»ƒm tra thá»‘ng kÃª dá»¯ liá»‡u trong Gold layer

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Thá»‘ng kÃª dá»¯ liá»‡u** | ToÃ n bá»™ file | Äáº¿m records, Æ°á»›c lÆ°á»£ng size, phÃ¢n tÃ­ch 5V Big Data, thá»‘ng kÃª theo quá»‘c gia |

**CÃ¡ch cháº¡y:**
```bash
python ml_training/check_countries.py
```

---

## Web Application (Inference)

### ğŸ“„ File: `app.py`

**Nhiá»‡m vá»¥:** Flask web application cho inference (dá»± Ä‘oÃ¡n AQI real-time)

**Mapping vá»›i `openaq_kich_ban.md`:**

| Pháº§n trong MD | Code Location | MÃ´ táº£ |
|--------------|---------------|-------|
| **Inference Pipeline** - Fetch Current Data | `get_station_data()` (dÃ²ng ~700-830) | Gá»i OpenAQ API `/locations/{location_id}` vÃ  `/sensors/{sensor_id}/measurements/hourly` |
| **Inference Pipeline** - Fetch Historical Data | `get_station_data()` (dÃ²ng ~700-830) | Gá»i API vá»›i `datetime_from` = 1h, 24h, 168h trÆ°á»›c Ä‘á»ƒ láº¥y lag features |
| **Inference Pipeline** - Feature Engineering | `create_features_for_prediction()` (dÃ²ng ~400-600) | Táº¡o 22 features tá»« current vÃ  historical data |
| **Inference Pipeline** - Prediction | `get_station_data()` (dÃ²ng ~800-820) | Load model, predict `aqi_next`, tráº£ vá» káº¿t quáº£ |
| **API Endpoint** - `/api/station/<location_id>` | `get_station_data()` (dÃ²ng ~650-830) | Endpoint Ä‘á»ƒ láº¥y thÃ´ng tin tráº¡m vÃ  prediction |
| **API Endpoint** - `/api/latest/<country_code>` | `get_latest_data()` (dÃ²ng 832-1000) | Endpoint Ä‘á»ƒ láº¥y dá»¯ liá»‡u má»›i nháº¥t theo quá»‘c gia |
| **Frontend** | `templates/` vÃ  `static/` | HTML, CSS, JavaScript cho dashboard |

**CÃ¡c hÃ m quan trá»ng:**
- `create_features_for_prediction()`: Táº¡o features cho inference (22 features)
- `get_station_data()`: Endpoint chÃ­nh cho inference
- `get_latest_data()`: Endpoint láº¥y dá»¯ liá»‡u má»›i nháº¥t theo quá»‘c gia
- `get_recommendation()`: Táº¡o recommendation message dá»±a trÃªn AQI

**CÃ¡ch cháº¡y:**
```bash
python app.py
# Hoáº·c
./run_frontend.sh
```

---

## TÃ³m táº¯t Mapping nhanh

| Chá»©c nÄƒng | File chÃ­nh | HÃ m/Class chÃ­nh |
|-----------|-----------|-----------------|
| **Thu tháº­p dá»¯ liá»‡u** | `collect_data.py` | `get_alive_stations()`, `collect_historical_data()` |
| **TÃ­nh AQI** | `aqi_calculator.py` | `calculate_aqi_for_pollutant()`, `convert_unit_to_standard()` |
| **Bronze Layer** | `spark/batch_processor.py` | `process_kafka_to_bronze()` |
| **Silver Layer** | `spark/batch_processor.py` | `process_bronze_to_silver()` |
| **Gold Layer** | `spark/batch_processor.py` | `process_silver_to_gold()` |
| **Load ClickHouse** | `load_to_clickhouse.py` | `load_bronze_to_clickhouse()`, `load_silver_to_clickhouse()`, `load_gold_to_clickhouse()` |
| **ML Training** | `ml_training/data_loader.py` | `AirQualityDataLoader`, `create_features()` |
| **Inference** | `app.py` | `create_features_for_prediction()`, `get_station_data()` |
| **Setup** | `setup_minio_buckets.py` | `setup_minio()` |
| **Docker** | `docker-compose.yml` | Cáº¥u hÃ¬nh services |

---

## CÃ¡c file khÃ¡c

### ğŸ“„ File: `requirements.txt`
- Danh sÃ¡ch Python dependencies

### ğŸ“„ File: `cleanup_all_data.sh`
- Script Ä‘á»ƒ xÃ³a dá»¯ liá»‡u trong MinIO vÃ  ClickHouse (testing/cleanup)

### ğŸ“„ File: `run_frontend.sh`
- Script Ä‘á»ƒ cháº¡y Flask app

### ğŸ“„ File: `SLIDE_PREPARATION_GUIDE.md`
- HÆ°á»›ng dáº«n chuáº©n bá»‹ slide presentation (khÃ´ng pháº£i code)

### ğŸ“„ File: `openaq_kich_ban.md`
- Ká»‹ch báº£n há»‡ thá»‘ng (documentation, khÃ´ng pháº£i code)

---

**LÆ°u Ã½:** File nÃ y Ä‘Æ°á»£c táº¡o Ä‘á»ƒ há»— trá»£ tráº£ lá»i cÃ¢u há»i "pháº§n nÃ y code á»Ÿ Ä‘Ã¢u" khi giÃ¡o viÃªn há»i. Báº¡n cÃ³ thá»ƒ tra cá»©u nhanh báº±ng cÃ¡ch tÃ¬m pháº§n tÆ°Æ¡ng á»©ng trong `openaq_kich_ban.md` vÃ  xem mapping á»Ÿ trÃªn.

